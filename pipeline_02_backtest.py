"""
# ğŸ“Š pipeline_02_backtest.py â€” v7E ì•™ìƒë¸” ë°±í…ŒìŠ¤íŠ¸ (ë…ë¦½ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸)
#
# âš ï¸  ì‹¤í–‰ ë°©ë²•:
#   ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” pipeline_02_predict.pyì˜ ì½”ë“œ(ëª¨ë¸, í•¨ìˆ˜, í™˜ê²½)ì— ì˜ì¡´í•©ë‹ˆë‹¤.
#   ë°˜ë“œì‹œ ì•„ë˜ ìˆœì„œë¡œ ì‹¤í–‰í•˜ì„¸ìš”:
#
#   1. python pipeline_02_predict.py   â† ëª¨ë¸ & í™˜ê²½ ì„¸íŒ…
#   2. python pipeline_02_backtest.py  â† ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰
#
#   ë˜ëŠ” Colab/Jupyter ì—ì„œëŠ” pipeline_02 ì…€ë“¤ì„ ëª¨ë‘ ì‹¤í–‰í•œ ë’¤ ì´ íŒŒì¼ì„ ì‹¤í–‰í•˜ì„¸ìš”.
#
# ì¶œë ¥:
#   - ì½˜ì†”ì— BACKTEST SUMMARY ì¶œë ¥
#   - MODEL_DIR/backtest_v7e.png ì €ì¥
"""

# pipeline_02_predict.py ì˜ ì „ì—­ ë³€ìˆ˜/í•¨ìˆ˜(log, supabase, MODEL_DIR, ëª¨ë¸ ë¡œë”© í•¨ìˆ˜ ë“±)ê°€
# ì´ë¯¸ í˜„ì¬ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì— ì¡´ì¬í•œë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.
# ë§Œì•½ ë…ë¦½ ì‹¤í–‰í•  ê²½ìš° ì•„ë˜ exec ì¤„ì˜ ì£¼ì„ì„ í•´ì œí•˜ì„¸ìš”:
# exec(open('pipeline_02_predict.py', encoding='utf-8').read())

import io
import contextlib

# ============================================================
# ë°±í…ŒìŠ¤íŠ¸ (í‘œì¤€ ë°©ì‹: ê³¼ê±° í•™ìŠµ â†’ ë¯¸ë˜ ê²€ì¦)
# - ì•™ìƒë¸” ëª¨ë¸/ê°€ì¤‘ì¹˜/ì„¸íŒ… ê·¸ëŒ€ë¡œ ì‚¬ìš©
# - í•™ìŠµ ì¢…ë£Œì¼ ì´í›„ êµ¬ê°„ë§Œ í…ŒìŠ¤íŠ¸ (ë°ì´í„° ìœ ì¶œ ì—†ìŒ)
# ============================================================

# ì˜µì…˜ (ê¸°ì¡´ ë…¸íŠ¸ë¶ ì„¸íŒ…ê³¼ ë™ì¼)
TRAINING_END_DATE = "2024-02-21"  # ëª¨ë¸ í•™ìŠµ ì¢…ë£Œì¼ (ì´ ë‚ ì§œ ì´í›„ë§Œ í…ŒìŠ¤íŠ¸, ê³¼ê±°â†’ë¯¸ë˜)
BACKTEST_DAYS = 365               # ë°±í…ŒìŠ¤íŠ¸ ê¸°ê°„ (1ë…„)
INITIAL_CAPITAL_KRW = 10_000_000
FEE_RATE = 0.00189                # ì—…ë¹„íŠ¸ ì›í™”: 0.05% + 0.139%
CONFIDENCE_THRESHOLD = 0.52       # ìµœì†Œ ì‹ ë¢°ë„ (ì´ ì´ìƒì¼ ë•Œë§Œ ë§¤ë§¤, ë¶ˆí™•ì‹¤ êµ¬ê°„ ìŠ¤í‚µ)

def run_backtest_v7e():
    """v7E ì•™ìƒë¸” ëª¨ë¸ë¡œ ë°±í…ŒìŠ¤íŠ¸ (í‘œì¤€ ë°©ì‹: ê³¼ê±° í•™ìŠµ â†’ ë¯¸ë˜ ê²€ì¦)"""
    log('ë°±í…ŒìŠ¤íŠ¸ ì‹œì‘ (v7E ì•™ìƒë¸”, ê³¼ê±°â†’ë¯¸ë˜ ê²€ì¦)', important=True)
    
    if 'supabase' not in globals() or supabase is None:
        log('Supabaseê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìœ„ ì…€ë“¤ì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.')
        return
    
    # 1. ìµœì‹  ë‚ ì§œ ë° ë°±í…ŒìŠ¤íŠ¸ êµ¬ê°„ (ê³¼ê±° í•™ìŠµ â†’ ë¯¸ë˜ ê²€ì¦)
    latest_date = get_latest_date_from_supabase()
    if latest_date is None:
        log('Supabaseì—ì„œ ìµœì‹  ë‚ ì§œë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
        return
    if latest_date.tzinfo is None:
        latest_date = latest_date.replace(tzinfo=timezone.utc)
    
    backtest_end = latest_date - timedelta(hours=24)
    if backtest_end.tzinfo is not None:
        backtest_end = backtest_end.tz_localize(None)
    backtest_start = max(
        pd.to_datetime(TRAINING_END_DATE),
        backtest_end - timedelta(days=BACKTEST_DAYS)
    )
    if backtest_start.tzinfo is not None:
        backtest_start = backtest_start.tz_localize(None)
    
    load_start = backtest_start - timedelta(hours=96)  # 72h history + 24h buffer
    load_end = backtest_end + timedelta(hours=24)      # ë§ˆì§€ë§‰ í¬ì§€ì…˜ ì²­ì‚°ìš© close í•„ìš”
    
    log(f'ë°±í…ŒìŠ¤íŠ¸ êµ¬ê°„: {backtest_start.strftime("%Y-%m-%d")} ~ {backtest_end.strftime("%Y-%m-%d")} (í•™ìŠµ ì¢…ë£Œì¼ ì´í›„)')
    
    # 2. ë°ì´í„° ë¡œë“œ (ë°±í…ŒìŠ¤íŠ¸ + 72h history + 24h ì²­ì‚°ìš©)
    all_rows, offset = [], 0
    start_str = load_start.strftime('%Y-%m-%d %H:%M:%S')
    end_str = load_end.strftime('%Y-%m-%d %H:%M:%S')
    while True:
        result = supabase.table('features_master').select('*').gte('date', start_str).lte('date', end_str).order('date').range(offset, offset + 999).execute()
        if not result.data:
            break
        all_rows.extend(result.data)
        offset += len(result.data)
        if len(result.data) < 1000:
            break
    if not all_rows:
        log('ë°±í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.')
        return
    
    df = pd.DataFrame(all_rows)
    df['date'] = pd.to_datetime(df['date'])
    if pd.api.types.is_datetime64tz_dtype(df['date']):
        df['date'] = df['date'].dt.tz_localize(None)
    df = df.sort_values('date').reset_index(drop=True)
    
    # ê°ì„± ë³‘í•©
    df_sent = fetch_sentiment_data()
    if not df_sent.empty:
        for col in ['sentiment_score', 'impact_score']:
            if col in df.columns:
                df = df.drop(columns=[col], errors='ignore')
        df = pd.merge(df, df_sent, on='date', how='left')
    df['sentiment_score'] = df.get('sentiment_score', 0).fillna(0)
    df['impact_score'] = df.get('impact_score', 0.5).fillna(0.5)
    
    if 'close' not in df.columns and 'close_price' in df.columns:
        df['close'] = df['close_price']
    df['close'] = pd.to_numeric(df['close'], errors='coerce')
    df = add_on_the_fly_features(df)
    
    # 3. ëª¨ë¸ ë¡œë“œ (ë°ì´í„° ìœ ì¶œ ë°©ì§€: ë””ìŠ¤í¬ ì›ë³¸ë§Œ ì‚¬ìš©, ì¦ë¶„ í•™ìŠµ X)
    log('ëª¨ë¸ ë¡œë“œ ì¤‘ (ë””ìŠ¤í¬ ì›ë³¸)...')
    models = load_all_models(df_full=df)
    features = models['features']
    
    # 4. ë¡¤ë§ ì˜ˆì¸¡ (stdout ì–µì œ)
    seq_len = config.PRIMARY_SEQUENCE_LENGTH
    preds = {}
    for i in range(seq_len - 1, len(df) - 24):
        row_date = df['date'].iloc[i]
        if row_date < backtest_start or row_date > backtest_end:
            continue
        df_slice = df.iloc[max(0, i - seq_len + 1):i + 1].copy()
        for f in features['catboost']:
            if f not in df_slice.columns:
                df_slice[f] = 0
        for f in features['cnnlstm']:
            if f not in df_slice.columns:
                df_slice[f] = 0
        for f in features['patchtst']:
            if f not in df_slice.columns:
                df_slice[f] = 0
        X_cat = models['scaler_catboost'].transform(df_slice[features['catboost']].fillna(0).values)
        X_cnn = models['scaler_cnnlstm'].transform(df_slice[features['cnnlstm']].fillna(0).values)
        X_patch = models['scaler_patchtst'].transform(df_slice[features['patchtst']].fillna(0).values)
        X_latest_cat = X_cat[[-1]]
        X_seq_cnn = X_cnn[-seq_len:]
        X_seq_patch = X_patch[-seq_len:]
        with contextlib.redirect_stdout(io.StringIO()):
            pred, confidence, _ = ensemble_predict_v7e(models, X_latest_cat, X_seq_cnn, X_seq_patch, df_slice)
        if confidence >= CONFIDENCE_THRESHOLD:
            preds[i] = pred
            if len(preds) % 1000 == 0:
                log(f'  ì˜ˆì¸¡ ì§„í–‰: {len(preds):,}ê°œ')
    
    log(f'ì´ {len(preds):,}ê°œ ì‹œì  ì˜ˆì¸¡ ì™„ë£Œ')
    
    # 5. ìˆ˜ìµë¥  ê³„ì‚° (24h ê²¹ì¹¨, í¬ì§€ì…˜ë‹¹ capital/24)
    cum_return = 0.0
    equity_curve = [INITIAL_CAPITAL_KRW]
    date_curve = [backtest_start]
    close_arr = df['close'].values
    wins, total = 0, 0
    for i in sorted(preds.keys()):
        c0, c24 = float(close_arr[i]), float(close_arr[i + 24])
        pred = preds[i]
        if pred == 1:  # UP (ë¡±)
            ret = (c24 - c0) / c0
        else:  # DOWN (ìˆ)
            ret = (c0 - c24) / c0
        ret_after_fee = ret - FEE_RATE
        cum_return += ret_after_fee / 24
        equity_curve.append(INITIAL_CAPITAL_KRW * (1 + cum_return))
        date_curve.append(df['date'].iloc[i + 24])
        total += 1
        if ret_after_fee > 0:
            wins += 1
    
    # 6. ê²°ê³¼ ìš”ì•½ + MDD ë“± ì¶”ê°€ ì§€í‘œ
    final_equity = equity_curve[-1] if equity_curve else INITIAL_CAPITAL_KRW
    total_ret_pct = (final_equity / INITIAL_CAPITAL_KRW - 1) * 100
    win_rate = (wins / total * 100) if total > 0 else 0
    
    eq_arr = np.array(equity_curve)
    peak = np.maximum.accumulate(eq_arr)
    drawdown_pct = (eq_arr - peak) / peak * 100
    mdd_pct = float(np.min(drawdown_pct))
    days_bt = (date_curve[-1] - date_curve[0]).total_seconds() / 86400 if len(date_curve) > 1 else 1
    cagr_pct = ((final_equity / INITIAL_CAPITAL_KRW) ** (365 / max(days_bt, 1)) - 1) * 100 if days_bt > 0 else 0
    
    returns_per_trade = []
    for i in sorted(preds.keys()):
        c0, c24 = float(close_arr[i]), float(close_arr[i + 24])
        pred = preds[i]
        ret = (c24 - c0) / c0 if pred == 1 else (c0 - c24) / c0
        returns_per_trade.append(ret - FEE_RATE)
    ret_std = float(np.std(returns_per_trade)) * 100 if returns_per_trade else 0
    mean_ret = float(np.mean(returns_per_trade)) * 100 if returns_per_trade else 0
    trades_per_day = len(returns_per_trade) / max(days_bt, 1)
    sharpe = (mean_ret / (ret_std + 1e-9)) * np.sqrt(365 * trades_per_day) if ret_std > 0 else 0
    
    log(f'ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼: {total:,}ê±´ | ìŠ¹ë¥  {win_rate:.1f}% | ì´ìˆ˜ìµë¥  {total_ret_pct:+.2f}% | ìµœì¢… {final_equity/1e6:.2f}ë°±ë§Œì›')
    
    # 7. í…ìŠ¤íŠ¸ ìš”ì•½
    summary = f'''
========== BACKTEST SUMMARY ==========
Period      : {backtest_start.strftime("%Y-%m-%d")} ~ {backtest_end.strftime("%Y-%m-%d")} ({days_bt:.0f} days)
Trades      : {total:,} (confidence>={CONFIDENCE_THRESHOLD})
Win Rate    : {win_rate:.1f}%

--- Strategy (Long/Short) ---
  Long when UP predicted, Short when DOWN predicted. 24h hold per position.
Initial     : {INITIAL_CAPITAL_KRW/1e6:.2f}M KRW
Final       : {final_equity/1e6:.2f}M KRW
Total Return: {total_ret_pct:+.2f}%
CAGR        : {cagr_pct:+.2f}%

--- Risk ---
MDD         : {mdd_pct:.2f}%
Sharpe      : {sharpe:.2f}
Volatility  : {ret_std:.2f}% (per trade)

--- Tuning Tips ---
  - CONFIDENCE_THRESHOLD: Higher (e.g. 0.55) = fewer trades, potentially higher quality
  - Lower = more trades, may increase noise
======================================
'''
    print(summary)
    
    # 8. ì°¨íŠ¸ (ì˜ë¬¸, MDD í¬í•¨)
    df_bt = df[(df['date'] >= backtest_start) & (df['date'] <= backtest_end)]
    if df_bt.empty or len(date_curve) < 2:
        log('ì°¨íŠ¸ ìƒì„±í•  ë°ì´í„° ë¶€ì¡±')
        return
    
    close_bt = df_bt['close'].values.astype(float)
    btc_index = (close_bt / close_bt[0]) * 100
    dates_bt = df_bt['date'].values
    
    import matplotlib.pyplot as plt
    fig, axes = plt.subplots(2, 1, figsize=(14, 9), height_ratios=[1.5, 0.8], sharex=True)
    ax1, ax2 = axes[0], axes[1]
    
    ax1.plot(dates_bt, btc_index, color='gray', alpha=0.7, label='BTC (100=Start)')
    eq_dates = pd.to_datetime(date_curve)
    eq_pct = (np.array(equity_curve) / INITIAL_CAPITAL_KRW) * 100
    ax1.plot(eq_dates, eq_pct, color='#22c55e', linewidth=2, label=f'Strategy ({final_equity/1e6:.1f}M)')
    ax1.axhline(100, color='gray', linestyle='--', alpha=0.5)
    ax1.set_ylabel('Index (100=Initial)')
    ax1.legend(loc='upper left')
    ax1.grid(True, alpha=0.3)
    ax1.set_title(f'v7E Backtest ({backtest_start.strftime("%Y-%m-%d")} ~ {backtest_end.strftime("%Y-%m-%d")}) | Return {total_ret_pct:+.2f}% | MDD {mdd_pct:.2f}% | Long/Short')
    
    ax2.fill_between(eq_dates, drawdown_pct, 0, color='#ef4444', alpha=0.5)
    ax2.plot(eq_dates, drawdown_pct, color='#dc2626', linewidth=1)
    ax2.set_ylabel('Drawdown (%)')
    ax2.set_xlabel('Date')
    ax2.grid(True, alpha=0.3)
    ax2.set_title('Maximum Drawdown')
    
    plt.tight_layout()
    
    save_path = os.path.join(MODEL_DIR, 'backtest_v7e.png')
    plt.savefig(save_path, dpi=150, bbox_inches='tight', facecolor='white')
    log(f'ì°¨íŠ¸ ì €ì¥: {save_path}')
    plt.show()


# ==========================================
# ì‹¤í–‰
# ==========================================
if __name__ == '__main__':
    run_backtest_v7e()
