# # ğŸ”® Weekly BTC Active/Quiet Prediction - v3.5 Load
# **monster_kaggle_weekly_v3.5 ê°€ì¤‘ì¹˜ ë¡œë“œ â†’ ì˜ˆì¸¡ â†’ DB ì €ì¥**
# 
# ## ğŸ¯ ì£¼ìš” ê¸°ëŠ¥:
# 1. ğŸ“Š Supabase features_daily ë¡œë“œ
# 2. ğŸ¤– ê°€ì¤‘ì¹˜ ë¡œë“œ (CatBoost 5-Fold, PatchTST 5-Fold)
# 3. ğŸ”® ë‹¤ìŒ 7ì¼ Active/Quiet ì˜ˆì¸¡
# 4. ğŸ’¾ weekly_predictions í…Œì´ë¸”ì— ì €ì¥
# 
# ## ğŸ“‹ í•„ìš”í•œ ê°€ì¤‘ì¹˜ íŒŒì¼ (Google Drive):
# `2526_Winter_Sideproject/models/production/weekly_v35/`
# - catboost_f0.cbm ~ catboost_f4.cbm
# - patchtst_f0.pth ~ patchtst_f4.pth
# - scalers_weekly.pkl
# - model_features_weekly.json

# ## ğŸ“¦ 0. íŒ¨í‚¤ì§€ ì„¤ì¹˜ & ì„í¬íŠ¸



# ==========================================
# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
# ==========================================
import os
import sys
import json
import pickle
import warnings
from datetime import datetime, timezone, timedelta

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.nn.functional as F

from sklearn.preprocessing import RobustScaler
from catboost import CatBoostClassifier

warnings.filterwarnings('ignore')

KST = timezone(timedelta(hours=9))

def log(message, important=False):
    kst_now = datetime.now(KST).strftime('%Y-%m-%d %H:%M:%S')
    msg = str(message)
    if important:
        print(f'\n{"*"*60}')
        print(f'[{kst_now}] â­ {msg}')
        print(f'{"*"*60}')
    else:
        print(f'[{kst_now}] {msg}')
    sys.stdout.flush()

log('âœ… íŒ¨í‚¤ì§€ ì„í¬íŠ¸ ì™„ë£Œ')

# ## ğŸ› ï¸ 1. í™˜ê²½ ì„¤ì • & Supabase (.env)

# ==============================================================================
# ğŸ” 1. ì–´ë–¤ í™˜ê²½ì—ì„œë“  ì•Œì•„ì„œ í‚¤ë¥¼ ì°¾ì•„ì˜¤ëŠ” í•˜ì´ë¸Œë¦¬ë“œ ë¡œë“œ êµ¬ì„±
# ==============================================================================
import sys
import os

IS_COLAB = 'google.colab' in sys.modules
IS_KAGGLE = 'kaggle_secrets' in sys.modules or os.path.exists('/kaggle/working')
IS_GITHUB_ACTIONS = os.getenv('GITHUB_ACTIONS') == 'true'

# [ë¡œì»¬ & ê¸°ì¡´ Colab ë“œë¼ì´ë¸Œ ì‚¬ìš©ììš©] .env íŒŒì¼ ë¡œë“œ
try:
    from dotenv import load_dotenv
    for env_path in ['/content/drive/MyDrive/2526Winter_Sideproject/.env', '.env', '/content/.env']:
        if os.path.exists(env_path):
            load_dotenv(env_path)
            log(f"ğŸ”§ .env íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {env_path}")
            break
except ImportError:
    pass

# [Colab Secrets / Kaggle Secrets ì „ìš© ì‚¬ìš©ììš©]
if IS_COLAB:
    from google.colab import drive, userdata
    drive.mount('/content/drive')
    os.environ['PROJECT_ROOT'] = '/content/drive/MyDrive/2526Winter_Sideproject'
    for key in ['SUPABASE_URL', 'SUPABASE_KEY', 'SUPABASE_SERVICE_KEY', 'OPENAI_API_KEY']:
        try:
            val = userdata.get(key)
            if val: os.environ[key] = val
        except: pass
elif IS_KAGGLE:
    from kaggle_secrets import UserSecretsClient
    user_secrets = UserSecretsClient()
    os.environ['PROJECT_ROOT'] = '/kaggle/working'
    for key in ['SUPABASE_URL', 'SUPABASE_KEY', 'SUPABASE_SERVICE_KEY', 'OPENAI_API_KEY']:
        try:
            val = user_secrets.get_secret(key)
            if val: os.environ[key] = val
        except: pass
elif IS_GITHUB_ACTIONS:
    os.environ['PROJECT_ROOT'] = os.getenv('GITHUB_WORKSPACE', os.getcwd())
else:
    os.environ['PROJECT_ROOT'] = os.getcwd()

# ==============================================================================
# ğŸš€ 2. ë³€ìˆ˜ í• ë‹¹ ë° ëª¨ë¸/Supabase ì—°ê²°
# ==============================================================================
PROJECT_ROOT = os.getenv("PROJECT_ROOT", os.getcwd())
MODEL_DIR = os.path.join(PROJECT_ROOT, 'models', 'production', 'weekly_v35')

log(f'  PROJECT_ROOT: {PROJECT_ROOT}')
log(f'  MODEL_DIR: {MODEL_DIR}')

if not os.path.exists(MODEL_DIR):
    # ê²½ê³ ë§Œ í•´ë‘ê³  ë‚˜ì¤‘ì— ì“¸ìˆ˜ìˆê²Œ
    log(f'âš ï¸ ëª¨ë¸ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {MODEL_DIR}')
else:
    files_in_dir = os.listdir(MODEL_DIR)
    log(f'  íŒŒì¼ ëª©ë¡: {files_in_dir}')

# Supabase ì—°ê²°
SUPABASE_URL = os.getenv("SUPABASE_URL")
SERVICE_KEY = os.getenv("SUPABASE_SERVICE_KEY", os.getenv("SUPABASE_KEY")) 
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not SUPABASE_URL or not SERVICE_KEY:
    raise ValueError("âŒ ì¹˜ëª…ì  ì˜¤ë¥˜: SUPABASE_URL ë˜ëŠ” SUPABASE_SERVICE_KEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")

from supabase import create_client
supabase = create_client(SUPABASE_URL, SERVICE_KEY)

log("âœ… Supabase ë§ˆìŠ¤í„° ê¶Œí•œ(Service Role) ì—°ê²° ì„±ê³µ ğŸ”“")

# ==============================================================================
# ğŸ“¥ [GitHub Actions ì „ìš©] Supabase Storageì—ì„œ ì£¼ê°„ ëª¨ë¸ ê°€ì¤‘ì¹˜ ìë™ ë‹¤ìš´ë¡œë“œ
# ==============================================================================
if IS_GITHUB_ACTIONS:
    log("ğŸ”½ GitHub Actions: Supabase Storageì—ì„œ ì£¼ê°„ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë‹¤ìš´ë¡œë“œ ì‹œì‘...", important=True)
    os.makedirs(MODEL_DIR, exist_ok=True)
    STORAGE_BUCKET = "models"
    STORAGE_FOLDER = "weekly_v35"
    FILES_TO_DOWNLOAD = [
        "catboost_f0.cbm", "catboost_f1.cbm", "catboost_f2.cbm", "catboost_f3.cbm", "catboost_f4.cbm",
        "patchtst_f0.pth", "patchtst_f1.pth", "patchtst_f2.pth", "patchtst_f3.pth", "patchtst_f4.pth",
        "scalers_weekly.pkl", "model_features_weekly.json",
    ]
    for filename in FILES_TO_DOWNLOAD:
        dest_path = os.path.join(MODEL_DIR, filename)
        if os.path.exists(dest_path):
            log(f"  âœ… ì´ë¯¸ ì¡´ì¬: {filename}")
            continue
        try:
            storage_path = f"{STORAGE_FOLDER}/{filename}"
            data = supabase.storage.from_(STORAGE_BUCKET).download(storage_path)
            with open(dest_path, "wb") as f:
                f.write(data)
            log(f"  âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {filename} ({len(data):,} bytes)")
        except Exception as e:
            log(f"  âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {filename} â†’ {e}")
            raise
    log("ğŸ‰ ëª¨ë“  ì£¼ê°„ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!", important=True)



# ## âš™ï¸ 2. Config & PatchTST ì•„í‚¤í…ì²˜ (v3.5)

# ==========================================
# Config - monster_kaggle_weekly_v3.5ì™€ ë™ì¼
# ==========================================
class Config:
    SEQ_LEN = 26
    HORIZON = 7
    NUM_CLASSES = 2
    D_MODEL = 128
    N_HEADS = 4
    N_LAYERS = 4
    PATCH_LEN = 7
    STRIDE = 3
    DROPOUT = 0.4
    USE_REVIN = True
    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

cfg = Config()
log(f'Config: SEQ_LEN={cfg.SEQ_LEN}, DEVICE={cfg.DEVICE}')

# ==========================================
# RevIN + EnhancedPatchTST (v3.5)
# ==========================================
class RevIN(nn.Module):
    def __init__(self, n_features, eps=1e-5, affine=True):
        super().__init__()
        self.eps, self.affine = eps, affine
        if affine:
            self.gamma = nn.Parameter(torch.ones(n_features))
            self.beta = nn.Parameter(torch.zeros(n_features))

    def forward(self, x, mode='norm'):
        if mode == 'norm':
            self.mean = x.mean(dim=1, keepdim=True)
            self.std = x.std(dim=1, keepdim=True) + self.eps
            x = (x - self.mean) / self.std
            if self.affine:
                x = x * self.gamma + self.beta
        elif mode == 'denorm':
            if self.affine:
                x = (x - self.beta) / self.gamma
            x = x * self.std + self.mean
        return x


class EnhancedPatchTST(nn.Module):
    def __init__(self, n_feat, seq_len):
        super().__init__()
        self.revin = RevIN(n_feat) if cfg.USE_REVIN else None
        self.n_patches = (seq_len - cfg.PATCH_LEN) // cfg.STRIDE + 1
        self.embed = nn.Sequential(
            nn.Linear(cfg.PATCH_LEN * n_feat, cfg.D_MODEL),
            nn.LayerNorm(cfg.D_MODEL), nn.GELU(), nn.Dropout(cfg.DROPOUT)
        )
        self.pos = nn.Parameter(torch.randn(1, self.n_patches, cfg.D_MODEL))
        enc = nn.TransformerEncoderLayer(
            cfg.D_MODEL, cfg.N_HEADS, cfg.D_MODEL * 4,
            cfg.DROPOUT, activation='gelu', batch_first=True, norm_first=True
        )
        self.trans = nn.TransformerEncoder(enc, cfg.N_LAYERS)
        self.classifier = nn.Sequential(
            nn.LayerNorm(cfg.D_MODEL),
            nn.Linear(cfg.D_MODEL, cfg.D_MODEL // 2), nn.GELU(), nn.Dropout(cfg.DROPOUT),
            nn.Linear(cfg.D_MODEL // 2, cfg.D_MODEL // 4), nn.GELU(), nn.Dropout(cfg.DROPOUT),
            nn.Linear(cfg.D_MODEL // 4, cfg.NUM_CLASSES)
        )

    def forward(self, x):
        if self.revin:
            x = self.revin(x, 'norm')
        B = x.shape[0]
        patches = [x[:, i * cfg.STRIDE:i * cfg.STRIDE + cfg.PATCH_LEN, :].reshape(B, -1)
                  for i in range(self.n_patches)]
        x = self.embed(torch.stack(patches, dim=1)) + self.pos
        x = self.trans(x)
        return self.classifier(x.mean(dim=1) + x.max(dim=1)[0])

log('âœ… PatchTST ì•„í‚¤í…ì²˜ ì •ì˜ ì™„ë£Œ')

# ## ğŸ¤– 3. ëª¨ë¸ ë¡œë“œ

# ==========================================
# model_features_weekly.json ë¡œë“œ
# ==========================================
features_path = os.path.join(MODEL_DIR, 'model_features_weekly.json')
with open(features_path, 'r') as f:
    meta = json.load(f)

feat_cat = meta['catboost']
feat_patch = meta['patchtst']
active_threshold = meta['active_threshold']
best_strategy = meta.get('best_strategy', 'A: Simple Avg')
boundary = meta.get('boundary', 0.02)
target_hits = meta.get('target_hits', 4)
model_version = meta.get('version', 'v3.5')

log(f'í”¼ì²˜: CatBoost={len(feat_cat)}, PatchTST={len(feat_patch)}')
log(f'active_threshold={active_threshold}, best_strategy={best_strategy}')

# ==========================================
# scalers_weekly.pkl ë¡œë“œ
# ==========================================
scalers_path = os.path.join(MODEL_DIR, 'scalers_weekly.pkl')
with open(scalers_path, 'rb') as f:
    scalers = pickle.load(f)

sc_cat = scalers['catboost']
sc_patch = scalers['patchtst']
log('âœ… ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì™„ë£Œ')

# ==========================================
# CatBoost 5-Fold ë¡œë“œ
# ==========================================
cat_models = []
for fold in range(5):
    path = os.path.join(MODEL_DIR, f'catboost_f{fold}.cbm')
    if not os.path.exists(path):
        log(f'  âš ï¸ {path} ì—†ìŒ')
        continue
    m = CatBoostClassifier()
    m.load_model(path)
    cat_models.append(m)

if len(cat_models) == 0:
    raise FileNotFoundError('CatBoost ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. catboost_f0.cbm ~ f4.cbmì„ MODEL_DIRì— ë„£ì–´ì£¼ì„¸ìš”.')
log(f'âœ… CatBoost: {len(cat_models)}/5 fold ë¡œë“œ')

# ==========================================
# PatchTST 5-Fold ë¡œë“œ
# ==========================================
patch_models = []
for fold in range(5):
    path = os.path.join(MODEL_DIR, f'patchtst_f{fold}.pth')
    if not os.path.exists(path):
        log(f'  âš ï¸ {path} ì—†ìŒ')
        continue
    model = EnhancedPatchTST(len(feat_patch), cfg.SEQ_LEN)
    ckpt = torch.load(path, map_location=cfg.DEVICE, weights_only=False)
    model.load_state_dict(ckpt['model_state_dict'], strict=False)
    model = model.to(cfg.DEVICE)
    model.eval()
    patch_models.append(model)

if len(patch_models) == 0:
    raise FileNotFoundError('PatchTST ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. patchtst_f0.pth ~ f4.pthë¥¼ MODEL_DIRì— ë„£ì–´ì£¼ì„¸ìš”.')
log(f'âœ… PatchTST: {len(patch_models)}/5 fold ë¡œë“œ')

# ## ğŸ“Š 4. ë°ì´í„° ë¡œë“œ & Regime í”¼ì²˜

# ==========================================
# features_daily ë¡œë“œ
# ==========================================
def fetch_features_daily():
    log('Loading features_daily...')
    all_rows, offset = [], 0
    while True:
        result = supabase.table('features_daily').select('*').order('date').range(offset, offset + 999).execute()
        if not result.data:
            break
        all_rows.extend(result.data)
        if len(result.data) < 1000:
            break
        offset += 1000
    df = pd.DataFrame(all_rows)
    df['date'] = pd.to_datetime(df['date'])
    df = df.sort_values('date').reset_index(drop=True)
    log(f'  {len(df):,} rows ({df["date"].min().date()} ~ {df["date"].max().date()})')
    return df

df_full = fetch_features_daily()

if len(df_full) < cfg.SEQ_LEN:
    raise ValueError(f'ë°ì´í„° ë¶€ì¡±: {len(df_full)}í–‰ (ìµœì†Œ {cfg.SEQ_LEN}í–‰ í•„ìš”)')

# ==========================================
# Regime í”¼ì²˜ ìƒì„± (monster_kaggle_weekly Cell 4)
# ==========================================
for col in ['vol_lag_24', 'vol_lag_48']:
    if col in df_full.columns:
        df_full[col] = df_full[col].clip(-10.0, 10.0)

daily_ret = df_full['close'].pct_change()
rolling_vol = daily_ret.rolling(26).std()

existing_cols = set(df_full.columns)
close = df_full['close']
sma20 = close.rolling(20).mean()
sma60 = close.rolling(60).mean()

def add_if_new(col_name, series):
    if col_name not in existing_cols:
        df_full[col_name] = series
        existing_cols.add(col_name)

add_if_new('regime_bull_flag', ((close > sma20) & (sma20 > sma60)).astype(float))
add_if_new('regime_bear_flag', ((close < sma20) | (close < sma60 * 0.95)).astype(float))
vol_med_exp = rolling_vol.expanding(min_periods=26).median()
add_if_new('regime_highvol_flag', (rolling_vol > vol_med_exp).astype(float))
vol_std_exp = rolling_vol.expanding(min_periods=26).std()
add_if_new('vol_regime_zscore', ((rolling_vol - vol_med_exp) / (vol_std_exp + 1e-8)).clip(-3, 3))
low52 = close.rolling(52).min()
high52 = close.rolling(52).max()
add_if_new('price_52w_position', (close - low52) / (high52 - low52 + 1e-8))
add_if_new('volatility_26w', rolling_vol)

log('âœ… Regime í”¼ì²˜ ìƒì„± ì™„ë£Œ')

# ## ğŸ”® 5. ì˜ˆì¸¡

# ==========================================
# ì˜ˆì¸¡ ì…ë ¥ ì¤€ë¹„
# ==========================================
missing_cat = [f for f in feat_cat if f not in df_full.columns]
missing_patch = [f for f in feat_patch if f not in df_full.columns]
if missing_cat:
    log(f'  âš ï¸ CatBoost ëˆ„ë½ í”¼ì²˜: {missing_cat}')
    for f in missing_cat:
        df_full[f] = 0
if missing_patch:
    log(f'  âš ï¸ PatchTST ëˆ„ë½ í”¼ì²˜: {missing_patch}')
    for f in missing_patch:
        df_full[f] = 0

df_tail = df_full.tail(cfg.SEQ_LEN).copy()
X_patch_raw = df_tail[feat_patch].fillna(0).values
X_patch_scaled = sc_patch.transform(X_patch_raw)
X_patch_seq = torch.FloatTensor(X_patch_scaled).unsqueeze(0).to(cfg.DEVICE)

X_cat_raw = df_full.iloc[-1:][feat_cat].fillna(0).values
X_cat_scaled = sc_cat.transform(X_cat_raw)

last_date = df_full['date'].iloc[-1]
log(f'ì˜ˆì¸¡ ê¸°ì¤€ì¼: {last_date.date()}')

# ==========================================
# CatBoost 5-Fold ì˜ˆì¸¡ í‰ê· 
# ==========================================
p_cat_list = []
for m in cat_models:
    p = m.predict_proba(X_cat_scaled)
    p_cat_list.append(p)

p_cat = np.mean(p_cat_list, axis=0)
log(f'CatBoost P(Active)={p_cat[0, 1]:.4f}')

# ==========================================
# PatchTST 5-Fold ì˜ˆì¸¡ í‰ê· 
# ==========================================
p_patch_list = []
with torch.no_grad():
    for m in patch_models:
        out = m(X_patch_seq)
        p = torch.softmax(out, dim=1).cpu().numpy()
        p_patch_list.append(p)

p_patch = np.mean(p_patch_list, axis=0)
log(f'PatchTST P(Active)={p_patch[0, 1]:.4f}')

# ==========================================
# ì•™ìƒë¸” (best_strategy)
# ==========================================
if 'Simple' in best_strategy or 'A:' in best_strategy:
    probs = (p_cat + p_patch) / 2.0
elif 'B:' in best_strategy or 'OOF' in best_strategy:
    probs = (p_cat + p_patch) / 2.0
elif 'C:' in best_strategy or 'Confidence' in best_strategy:
    conf_cat = np.abs(p_cat[0, 1] - 0.5)
    conf_patch = np.abs(p_patch[0, 1] - 0.5)
    total_c = conf_cat + conf_patch + 1e-8
    probs = (conf_cat * p_cat + conf_patch * p_patch) / total_c
else:
    probs = (p_cat + p_patch) / 2.0

p_active = float(probs[0, 1])
prediction = 1 if p_active >= active_threshold else 0
confidence = max(p_active, 1 - p_active)

log('', important=True)
log(f'ğŸ¯ ì˜ˆì¸¡: {"ğŸŸ¢ ACTIVE" if prediction == 1 else "ğŸ”´ QUIET"}')
log(f'   P(Active)={p_active:.4f}, threshold={active_threshold}')
log(f'   ì‹ ë¢°ë„={confidence:.4f}')

# ## ğŸ’¾ 6. DB ì €ì¥ (weekly_predictions)

# ==========================================
# prediction_week_start = ëŒì•„ì˜¤ëŠ” ì›”ìš”ì¼
# (ë§¤ì£¼ ì¼ìš”ì¼ ì‹¤í–‰ ê¸°ì¤€: ì¼ìš”ì¼ â†’ ë‹¤ìŒë‚  ì›”ìš”ì¼ë¶€í„° í•œ ì£¼)
# ==========================================
today_kst = datetime.now(KST).date()

# weekday(): 0=ì›”, 1=í™”, ..., 6=ì¼
# ëŒì•„ì˜¤ëŠ” ì›”ìš”ì¼ê¹Œì§€ ë‚¨ì€ ì¼ìˆ˜
days_to_monday = (7 - today_kst.weekday()) % 7
if days_to_monday == 0:   # ì˜¤ëŠ˜ì´ ì›”ìš”ì¼ì´ë©´ â†’ ë‹¤ìŒ ì£¼ ì›”ìš”ì¼
    days_to_monday = 7
prediction_week_start = today_kst + timedelta(days=days_to_monday)  # ëŒì•„ì˜¤ëŠ” ì›”ìš”ì¼

log(f'ì˜ˆì¸¡ ê¸°ì¤€: ì˜¤ëŠ˜(ì‹¤í–‰) {today_kst} ({["ì›”","í™”","ìˆ˜","ëª©","ê¸ˆ","í† ","ì¼"][today_kst.weekday()]}) â†’ '
    f'ì˜ˆì¸¡ ì£¼ê°„ {prediction_week_start}(ì›”) ~ {prediction_week_start + timedelta(days=6)}(ì¼)')

# ==========================================
# weekly_predictions í…Œì´ë¸”ì— ì €ì¥
# ==========================================
data = {
    'prediction_week_start': prediction_week_start.isoformat(),
    'prediction': int(prediction),
    'p_active': float(p_active),
    'confidence': float(confidence),
    'boundary': float(boundary),
    'target_hits': int(target_hits),
    'model_version': model_version,
    'predicted_at': datetime.now(timezone.utc).isoformat(),
    'model_details': {
        'best_strategy': best_strategy,
        'active_threshold': active_threshold,
        'p_cat_active': float(p_cat[0, 1]),
        'p_patch_active': float(p_patch[0, 1]),
    }
}

try:
    supabase.table('weekly_predictions').upsert(data, on_conflict='prediction_week_start').execute()
    log('âœ… weekly_predictions ì €ì¥ ì™„ë£Œ', important=True)
except Exception as e:
    log(f'âŒ ì €ì¥ ì‹¤íŒ¨: {e}', important=True)
    raise

# ==========================================
# ìš”ì•½ ì¶œë ¥ (ì¼ì¼ ì˜ˆì¸¡ ì—°ë™ìš© ì°¸ì¡°)
# ==========================================
pred_end = prediction_week_start + timedelta(days=6)
print(f'\n{"="*60}')
print('ğŸ“‹ ì£¼ê°„ ì˜ˆì¸¡ ê²°ê³¼ ìš”ì•½')
print(f'{"="*60}')
print(f'  ì˜ˆì¸¡ ì£¼: {prediction_week_start} ~ {pred_end}')
print(f'  ê²°ê³¼: {"ACTIVE" if prediction == 1 else "QUIET"}')
print(f'  P(Active): {p_active:.4f}')
print(f'  ì‹ ë¢°ë„: {confidence:.4f}')
print(f'\n  [ê°œë³„ ëª¨ë¸] CatBoost P(Active)={p_cat[0,1]:.4f}  PatchTST P(Active)={p_patch[0,1]:.4f}')
print(f'  [ì •ì˜] BOUNDARY=Â±{boundary:.2%}, 7ì¼ ì¤‘ {target_hits}íšŒ ì´ìƒ í„°ì¹˜ â†’ Active')
print(f'  [ê±°ë˜ í•´ì„] {"ACTIVE â†’ ì¼ì¼ ì‹ í˜¸ ê³µê²©ì  í™œìš©" if prediction == 1 else "QUIET â†’ ì¼ì¼ ì‹ í˜¸ ë³´ìˆ˜ì  í™œìš©"}')
print(f'\n  â†’ 33_market_analysis_daily_weeklyì—ì„œ predictions + weekly_predictions ì¡°íšŒí•˜ì—¬ ì‹œì¥ ë¶„ì„')
print(f'{"="*60}')

# ## ğŸ“Œ ì°¸ê³ : DB ìŠ¤í‚¤ë§ˆ/ë°ì´í„° ì¡°íšŒ SQL
# 33_market_analysis_daily_weekly ì‘ì„± ì‹œ ì•„ë˜ SQLë¡œ ìŠ¤í‚¤ë§ˆ í™•ì¸ í›„, ê²°ê³¼ë¥¼ ê³µìœ í•´ì£¼ì„¸ìš”.

# ì•„ë˜ SQLì„ Supabase Dashboard > SQL Editorì—ì„œ ì‹¤í–‰ í›„, predictions ìŠ¤í‚¤ë§ˆ ê²°ê³¼ë¥¼ ë³µì‚¬í•´ì„œ ê³µìœ 
print('=== 1. predictions í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ì¡°íšŒ (ê²°ê³¼ ë³µì‚¬í•´ì„œ ê³µìœ ) ===')
print('''SELECT column_name, data_type, is_nullable
FROM information_schema.columns
WHERE table_name = 'predictions'
ORDER BY ordinal_position;''')
print()
print('=== 2. weekly_predictions í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ì¡°íšŒ ===')
print('''SELECT column_name, data_type, is_nullable
FROM information_schema.columns
WHERE table_name = 'weekly_predictions'
ORDER BY ordinal_position;''')
print()
print('=== 3. predictions ë°ì´í„° ì¡°íšŒ (ìµœê·¼ 30ê±´) ===')
print('''SELECT * FROM predictions ORDER BY date DESC LIMIT 30;''')
print()
print('=== 4. weekly_predictions ë°ì´í„° ì¡°íšŒ (ìµœê·¼ 10ê±´) ===')
print('''SELECT * FROM weekly_predictions ORDER BY prediction_week_start DESC LIMIT 10;''')
